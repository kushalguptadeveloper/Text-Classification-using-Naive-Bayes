{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data from directory, subdirectory and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19998\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "X = list()\n",
    "Y = list()\n",
    "for r,d,f in os.walk(r'''20_newsgroups'''):\n",
    "    for file in f:\n",
    "        X.append(os.path.join(r,file))\n",
    "print(len(X))\n",
    "\n",
    "\n",
    "for r,d,f in os.walk(r'''20_newsgroups'''):\n",
    "    for dirc in d:\n",
    "        Y.append(os.path.join(r,dirc))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = list()\n",
    "train_file = X\n",
    "for i in range(0,len(train_file),50):\n",
    "    test_file.append(train_file[i])\n",
    "for j in test_file:\n",
    "    train_file.remove(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19598"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file.pop(0)\n",
    "print(len(test_file))\n",
    "len(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20_newsgroups/.DS_Store'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a list of complete stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "839"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_i = [word.title() for word in stopwords]\n",
    "stopwords_u = [word.upper() for word in stopwords]\n",
    "others = [str(i) for i in range(101)] + [str(i)+\".\" for i in range(101)]\n",
    "sp = [\"''\",'\"\"',\"'\",'\"','!','~','`','!','@','#','$','%','^','&','*','/','-','+','_',':)','**','***','_/',\n",
    "      '----------------------------------------------------------------------',\n",
    "      '[]','{}','()','\\\\','|','[',']','(','|>','>>','<<',\n",
    "')','{','}',',','.','?','=','<=','>=','<','>',':',';','A','B','Q','W','E','R','T','Y','U','I','O','P','S','D','F',\n",
    "      'G','H','J','K','L','Z','X','C','V','N','M','A.','B.','Q.','W.','E.','R.','T.','Y.','U.','I.','O.','P.',\n",
    "      'S.','D.','F.','G.','H.','J.','K.','L.','Z.','X.','C.','V.','N.','M.']\n",
    "stopwords = stopwords + stopwords_i + stopwords_u + others + sp\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknz = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for k in train_file:\n",
    "    #with open(k, 'rb') as f:\n",
    "    #    text = f.read()\n",
    "        text = tknz.tokenize(open(k,errors = \"replace\").read())\n",
    "    #with open(k, encoding=\"utf8\", errors='ignore') as f:\n",
    "        #text = f.read()\n",
    "        for t in text:\n",
    "            if t not in stopwords:\n",
    "                if vocab.get(t) != None:\n",
    "                    vocab[t] += 1\n",
    "                else:\n",
    "                    vocab[t] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281630\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1cbfb8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = list(range(len(vocab.keys())))\n",
    "y_axis = list(vocab.values()) \n",
    "plt.scatter(x_axis,y_axis)\n",
    "#plt.axis([0,350000,0,50000])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sorting the vocab list in descending order on the basis of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vocab\n",
    "voc = sorted(voc.items(), key=lambda x: x[1], reverse=True) #Sorting the words according to their frequencies in the dataset\n",
    "col = voc[0:2000] #Choosing top 2000 most occuring words\n",
    "col = dict(col) \n",
    "columns = list(col.keys()) #list of all 2000 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a np array with total no. of training files as rows and total no. of vocab selected as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[0] * len(col) for i in range(len(train_file))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19598, 2000)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traversing through each file again and checking each word if it is in vocab then incrementing its frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(train_file)):\n",
    "    text = tknz.tokenize(open(train_file[k],errors = 'replace').read())\n",
    "    for t in text:\n",
    "        if t in columns:\n",
    "            pos = columns.index(t)\n",
    "            x_train[k][pos] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19598, 2000)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(x_train,columns = columns)\n",
    "y_train = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_file:\n",
    "    clas = i.split('/')[1]\n",
    "    y_train.append(clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19598,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating array for x_test and y_test as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([[0] * len(col) for i in range(len(test_file))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(test_file)):\n",
    "    text = tknz.tokenize(open(test_file[k],errors = 'replace').read())\n",
    "    for t in text:\n",
    "        if t in columns:\n",
    "            pos = columns.index(t)\n",
    "            x_test[k][pos] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 2000)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(x_test, columns = columns)\n",
    "y_test = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_file:\n",
    "    clas = i.split('/')[1]\n",
    "    y_test.append(clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399,)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sklearn = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.71      0.75      0.73        20\n",
      "           comp.graphics       0.62      0.80      0.70        20\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00        20\n",
      "comp.sys.ibm.pc.hardware       0.57      0.85      0.68        20\n",
      "   comp.sys.mac.hardware       0.90      0.95      0.93        20\n",
      "          comp.windows.x       0.88      0.75      0.81        20\n",
      "            misc.forsale       0.77      1.00      0.87        20\n",
      "               rec.autos       0.86      0.95      0.90        20\n",
      "         rec.motorcycles       0.86      0.95      0.90        20\n",
      "      rec.sport.baseball       0.95      0.95      0.95        20\n",
      "        rec.sport.hockey       1.00      0.95      0.97        20\n",
      "               sci.crypt       0.95      0.95      0.95        20\n",
      "         sci.electronics       0.90      0.95      0.93        20\n",
      "                 sci.med       0.95      0.95      0.95        20\n",
      "               sci.space       1.00      0.95      0.97        20\n",
      "  soc.religion.christian       0.95      1.00      0.97        19\n",
      "      talk.politics.guns       0.68      0.95      0.79        20\n",
      "   talk.politics.mideast       0.94      0.80      0.86        20\n",
      "      talk.politics.misc       1.00      0.55      0.71        20\n",
      "      talk.religion.misc       0.63      0.60      0.62        20\n",
      "\n",
      "             avg / total       0.81      0.83      0.81       399\n",
      "\n",
      "[[15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5]\n",
      " [ 1 16  0  1  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  4  0 11  0  2  2  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0 17  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0 15  1  0  0  0  0  0  1  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 19  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1 19  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0 19  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1 19  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0 19  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  1  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 19  0  0  0]\n",
      " [ 1  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  1 16  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  5  0 11  2]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  2  1  0 12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_sklearn))\n",
    "print(confusion_matrix(y_test, y_pred_sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#  Making a dictionary of groups to give them an integer value which shows class\n",
    "#  I have classified 20 groups into 6 classes viz, Religion, Computer, Vehicles, Sports, Politics and for_sale\n",
    "dic = {'alt.atheism':1,\n",
    " 'comp.graphics':2,\n",
    " 'comp.os.ms-windows.misc':2,\n",
    " 'comp.sys.ibm.pc.hardware':2,\n",
    " 'comp.sys.mac.hardware':2,\n",
    " 'comp.windows.x':2,\n",
    " 'misc.forsale':3,\n",
    " 'rec.autos':4,\n",
    " 'rec.motorcycles':4,\n",
    " 'rec.sport.baseball':4,\n",
    " 'rec.sport.hockey':4,\n",
    " 'sci.crypt':5,\n",
    " 'sci.electronics':5,\n",
    " 'sci.med':5,\n",
    " 'sci.space':5,\n",
    " 'soc.religion.christian':1,\n",
    " 'talk.politics.guns':6,\n",
    " 'talk.politics.mideast':6,\n",
    " 'talk.politics.misc':6,\n",
    " 'talk.religion.misc':1,\n",
    " '.DS_Store':3\n",
    "      }\n",
    "      '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "y_train_six = list()\n",
    "y_test_six = list()\n",
    "#test_file.pop(0)\n",
    "for group in train_file:\n",
    "    g = group.split('/')[1]\n",
    "    y_train_six.append(dic[g])\n",
    "                    \n",
    "for gr in test_file:\n",
    "    g1 = gr.split('/')[1]\n",
    "    \n",
    "    \n",
    "    y_test_six.append(dic[g1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.91      0.90      0.91        59\n",
      "          2       0.99      0.70      0.82       100\n",
      "          3       0.50      0.95      0.66        21\n",
      "          4       0.93      0.97      0.95        80\n",
      "          5       0.86      0.96      0.91        80\n",
      "          6       0.89      0.85      0.87        60\n",
      "\n",
      "avg / total       0.90      0.87      0.87       400\n",
      "\n",
      "[[53  0  0  0  0  6]\n",
      " [ 1 70 15  3 11  0]\n",
      " [ 0  1 20  0  0  0]\n",
      " [ 0  0  2 78  0  0]\n",
      " [ 1  0  1  1 77  0]\n",
      " [ 3  0  2  2  2 51]]\n"
     ]
    }
   ],
   "source": [
    "'''clf.fit(x_train,y_train_six)\n",
    "y_pred_sklearn_six = clf.predict(x_test)\n",
    "print(classification_report(y_test_six, y_pred_sklearn_six))\n",
    "print(confusion_matrix(y_test_six, y_pred_sklearn_six))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    dic = {}\n",
    "    possible_classes = set(y_train)\n",
    "    num_features = x_train.shape[1]\n",
    "    for current_class in possible_classes:\n",
    "        dic[current_class] = {}\n",
    "        current_class_rows = (y_train == current_class)\n",
    "        x_train_current = x_train[current_class_rows]\n",
    "        y_train_current = y_train[current_class_rows]\n",
    "        dic[\"total_data\"] = len(y_train)\n",
    "        output = 0\n",
    "        dic[current_class][\"y_total_count\"] = len(y_train_current)\n",
    "        for j in range(1, num_features+1):\n",
    "            dic[current_class][j] = x_train_current[:,j-1].sum()\n",
    "            output += dic[current_class][j]\n",
    "        dic[current_class][\"total_count\"] = output\n",
    "         \n",
    "    return dic        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(dictionary,x,current_class):\n",
    "    op = np.log(dictionary[current_class][\"y_total_count\"]) - np.log(dictionary[\"total_data\"])\n",
    "    num_features = len(dictionary[current_class].keys()) - 2\n",
    "    for j in range(1,num_features + 1):\n",
    "        if x[j-1] != 0:\n",
    "            count_current_class_current_word = dictionary[current_class][j] + 1\n",
    "            count_current_class = dictionary[current_class][\"total_count\"] + num_features\n",
    "            current_probability = np.log(count_current_class_current_word) - np.log(count_current_class)\n",
    "            op = op + current_probability\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_class(dictionary, x):\n",
    "    all_classes = dictionary.keys()\n",
    "    best_prob = -1000\n",
    "    best_class = \"\"\n",
    "    for current_class in all_classes:\n",
    "        if current_class == \"total_data\":\n",
    "            continue\n",
    "        current_class_prob = probability(dictionary,x,current_class)\n",
    "        if current_class_prob > best_prob:\n",
    "            best_prob = current_class_prob\n",
    "            best_class = current_class\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dictionary, x_test):\n",
    "    y_pred = list()\n",
    "    for x in x_test:\n",
    "        final_class = predict_single_class(dictionary,x)\n",
    "        y_pred.append(final_class)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_own_algo = predict(dic,x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                               0.00      0.00      0.00         0\n",
      "             alt.atheism       0.74      0.70      0.72        20\n",
      "           comp.graphics       0.56      0.75      0.64        20\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00        20\n",
      "comp.sys.ibm.pc.hardware       0.60      0.75      0.67        20\n",
      "   comp.sys.mac.hardware       0.82      0.90      0.86        20\n",
      "          comp.windows.x       0.88      0.75      0.81        20\n",
      "            misc.forsale       0.76      0.95      0.84        20\n",
      "               rec.autos       1.00      1.00      1.00        20\n",
      "         rec.motorcycles       0.87      1.00      0.93        20\n",
      "      rec.sport.baseball       0.95      0.95      0.95        20\n",
      "        rec.sport.hockey       1.00      0.95      0.97        20\n",
      "               sci.crypt       0.94      0.80      0.86        20\n",
      "         sci.electronics       0.78      0.90      0.84        20\n",
      "                 sci.med       1.00      0.85      0.92        20\n",
      "               sci.space       1.00      0.85      0.92        20\n",
      "  soc.religion.christian       1.00      1.00      1.00        19\n",
      "      talk.politics.guns       0.71      0.75      0.73        20\n",
      "   talk.politics.mideast       1.00      0.60      0.75        20\n",
      "      talk.politics.misc       0.67      0.40      0.50        20\n",
      "      talk.religion.misc       0.59      0.50      0.54        20\n",
      "\n",
      "             avg / total       0.79      0.77      0.77       399\n",
      "\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4]\n",
      " [ 2  0 15  0  1  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  6  0  9  0  2  1  0  0  0  0  0  1  0  0  0  0  0  1  0]\n",
      " [ 0  0  3  0 15  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0 18  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0 15  1  0  1  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0 19  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1 19  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0  0  0  1  0  0 16  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0 18  0  0  0  1  0  0  0]\n",
      " [ 1  1  1  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 15  0  0  0]\n",
      " [ 3  1  0  0  0  0  0  1  0  1  0  0  0  1  0  0  0  0 12  1  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  4  0  8  3]\n",
      " [ 4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  2 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_own_algo))\n",
    "print(confusion_matrix(y_test,y_pred_own_algo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
